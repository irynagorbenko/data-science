{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl5a1sNMyNJewC8pdV5SAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irynagorbenko/data-science/blob/opi-radiomics/logistic_regression_all_records.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SOGgInn94MmL"
      },
      "outputs": [],
      "source": [
        "# Read data from Google Drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "import mlxtend\n",
        "gc = gspread.authorize(creds)\n",
        "from google.colab import files\n",
        "\n",
        "# Open our new sheet and add some data.\n",
        "spreadsheet_t2w = gc.open_by_url('https://docs.google.com/spreadsheets/d/1PTjiajpfNcK3_S-t1_tZNT4Sr6dYjMaFzpQgS9FvYUU/edit#gid=0')\n",
        "rad_t2w= spreadsheet_t2w.worksheet('final_rad');\n",
        "\n",
        "spreadsheet_sr = gc.open_by_url('https://docs.google.com/spreadsheets/d/1VX48Vb9cYDHRT1iOfIrpKW2duWPGR6zguk5rGX5UeX0/edit#gid=0')\n",
        "sr= spreadsheet_sr.worksheet('final_SR');\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "# rows = rad_t2w.get('A1:AU1028')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "radDF = pd.DataFrame(rad_t2w.get_all_records())\n",
        "radDF.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Sx42Hg4TOe",
        "outputId": "761056c6-c46a-492d-a662-ddb6f86c8756"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(976, 47)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srDF = pd.DataFrame(sr.get_all_records())\n",
        "srDF.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHMrIFDI6_kP",
        "outputId": "70fa386b-ec70-42e0-a888-e7d15ada13e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(976, 68)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "radDF.head()"
      ],
      "metadata": {
        "id": "6niHvrmqQbBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "radDF.info()"
      ],
      "metadata": {
        "id": "RTl1hPp0BYp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srDF.info()"
      ],
      "metadata": {
        "id": "7pWtyynyB4nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = radDF[['original_firstorder_Energy']]\n",
        "y = srDF[['lesion_pirads']]\n",
        "idx = y[y['lesion_pirads'] == ''].index # empty pi-rads in line 183, 221, 796\n",
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm7EJZxdlOyn",
        "outputId": "11218bf0-b139-4c52-ff85-263aee3d23df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([183, 221, 796], dtype='int64')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.drop(idx) # independent variable - input\n",
        "y = y.drop(idx) # dependent variable - output"
      ],
      "metadata": {
        "id": "eRc48neCmAWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzwK8QE5nFG_",
        "outputId": "4af35d7a-dc79-4e80-ad1c-d64978ac8a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(973, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Distribution check**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B6jjZayo6lnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# matplotlib histogram\n",
        "# plt.hist(x, color = 'blue', edgecolor = 'black', bins = 50)#, bins = int(180/5))\n",
        "\n",
        "# seaborn histogram\n",
        "sns.distplot(x, hist=True, kde=False, bins = 80, color = 'blue', hist_kws={'edgecolor':'black'}) #bins=int(180/5), \n",
        "\n",
        "# Add labels\n",
        "plt.title('Histogram of original_firstorder_Energy')\n",
        "plt.xlabel('Energy')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "kFc7t56Q6u4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srDF[['patient_id', 'radiologist_id', 'patient_pirads']]"
      ],
      "metadata": {
        "id": "Zt0ohrxpDo6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "temprad = radDF[['patient_id', 'radiologist_id', 'original_firstorder_Energy']]\n",
        "tempsr = srDF[['patient_id', 'radiologist_id', 'patient_pirads']]\n",
        "idx = tempsr[tempsr['patient_pirads'] == ''].index\n",
        "temprad = temprad.drop(idx)\n",
        "tempsr = tempsr.drop(idx)\n",
        "\n",
        "tempDF = pd.merge(temprad, tempsr, on=[\"patient_id\", \"radiologist_id\"])\n",
        "\n",
        "sns.scatterplot(data=tempDF, x=\"original_firstorder_Energy\", y=\"patient_pirads\")#, hue=\"time\")"
      ],
      "metadata": {
        "id": "EJAhpS_ABvwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many studies of pi-rads in range 1 to 5 are in data\n",
        "\n",
        "pirads1 = tempDF['patient_pirads'].value_counts()[1]\n",
        "pirads2 = tempDF['patient_pirads'].value_counts()[2]\n",
        "pirads3 = tempDF['patient_pirads'].value_counts()[3]\n",
        "pirads4 = tempDF['patient_pirads'].value_counts()[4]\n",
        "pirads5 = tempDF['patient_pirads'].value_counts()[5]\n",
        "print(pirads1, pirads2, pirads3, pirads4, pirads5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dpEbFA_HN5k",
        "outputId": "03e00d48-fe8a-4a50-a9ca-05eab487a9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 32 118 468 631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=tempDF, x=\"patient_pirads\", y=\"original_firstorder_Energy\")"
      ],
      "metadata": {
        "id": "k_1em71VGXOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to_numpy()\n",
        "y = y.to_numpy().ravel()\n",
        "y = y.astype(str).astype(float).astype(int)"
      ],
      "metadata": {
        "id": "Kpy9ZGqopSnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors: Tom Dupre la Tour <tom.dupre-la-tour@m4x.org>\n",
        "# License: BSD 3 clause\n",
        "#!pip install -U scikit-learn\n",
        "#!pip install --upgrade scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "# make 3-class dataset for classification\n",
        "#centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
        "#X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
        "#transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
        "#X = np.dot(X, transformation)\n",
        "\n",
        "for multi_class in (\"multinomial\", \"ovr\"):\n",
        "    clf = LogisticRegression(solver=\"sag\", max_iter=100, random_state=42, multi_class=multi_class).fit(x, y)\n",
        "\n",
        "    # print the training scores\n",
        "    print(\"training score : %.3f (%s)\" % (clf.score(x, y), multi_class))\n",
        "\n",
        "    _, ax = plt.subplots()\n",
        "    DecisionBoundaryDisplay.from_estimator(clf, x, response_method=\"predict\", cmap=plt.cm.Paired, ax=ax)\n",
        "    plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
        "    plt.axis(\"tight\")\n",
        "\n",
        "    # Plot also the training points\n",
        "    colors = \"bry\"\n",
        "    for i, color in zip(clf.classes_, colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(\n",
        "            x[idx, 0], x[idx, 1], c=color, cmap=plt.cm.Paired, edgecolor=\"black\", s=20\n",
        "        )\n",
        "\n",
        "    # Plot the three one-against-all classifiers\n",
        "    xmin, xmax = plt.xlim()\n",
        "    ymin, ymax = plt.ylim()\n",
        "    coef = clf.coef_\n",
        "    intercept = clf.intercept_\n",
        "\n",
        "    def plot_hyperplane(c, color):\n",
        "        def line(x0):\n",
        "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
        "\n",
        "        plt.plot([xmin, xmax], [line(xmin), line(xmax)], ls=\"--\", color=color)\n",
        "\n",
        "    for i, color in zip(clf.classes_, colors):\n",
        "        plot_hyperplane(i, color)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PHuzBc7TAMDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**scikit-learn**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F0gdZLfgypbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for analysis in scikit-learn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "tMEVGKzOnRvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Example data\n",
        "\n",
        "# The input and output should be NumPy arrays\n",
        "#x = np.arange(10).reshape(-1, 1) # The array x is required to be two-dimensional. It should have one column for each input, and the number of rows should be equal to the number of observations. \n",
        "#y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]) # y is one-dimensional with ten items. Each item corresponds to one observation. It contains only zeros and ones since this is a binary classification problem.\n",
        "\n",
        "x = x.to_numpy()\n",
        "#y = y.to_numpy()\n",
        "\n",
        "y = y.to_numpy().ravel()"
      ],
      "metadata": {
        "id": "c_f1E3cInqI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.astype(str).astype(float).astype(int)"
      ],
      "metadata": {
        "id": "s4VDuAhyAg99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Model\n",
        "\n",
        "model = LogisticRegression(solver='saga')\n",
        "model.fit(x, y) # it fits the model and returns the model instance\n",
        "# Important parameters\n",
        "\n",
        "# penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
        "# C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
        "# class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
        "# solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
        "# max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
        "# multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
        "# warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
        "# n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
        "# l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n",
        "\n",
        "# Warning\n",
        "# 'liblinear' solver doesn’t work without regularization.\n",
        "#'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
        "#'saga' is the only solver that supports elastic-net regularization."
      ],
      "metadata": {
        "id": "7tZ_xLc0okfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the example of binary classification, and y can be 0 or 1\n",
        "model.classes_ "
      ],
      "metadata": {
        "id": "EF0irVIltSz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the intercept 𝑏₀ of the linear function 𝑓\n",
        "model.intercept_"
      ],
      "metadata": {
        "id": "OFWYxYhbtoJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the value of the slope 𝑏₁ of the linear function 𝑓\n",
        "model.coef_"
      ],
      "metadata": {
        "id": "KeRT3iXMtqGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Evaluate the Model\n",
        "\n",
        "model.predict_proba(x) # returns the matrix of probabilities that the predicted output is equal to zero or one\n",
        "\n",
        "# Each row corresponds to a single observation. \n",
        "# The first column is the probability of the predicted output being zero, that is 1 - 𝑝(𝑥). \n",
        "# The second column is the probability that the output is one, or 𝑝(𝑥)."
      ],
      "metadata": {
        "id": "HYoFAC2OuJ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The actual predictions, based on the probability matrix and the values of 𝑝(𝑥)\n",
        "model.predict(x)"
      ],
      "metadata": {
        "id": "3N5zxGYlusMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the ratio of the number of correct predictions to the number of observations\n",
        "model.score(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb5xmZfnvT-_",
        "outputId": "230aaf4a-54cb-4016-b2b4-77c9c327e453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45426515930113054"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "#In the case of binary classification, the confusion matrix shows the numbers of the following:\n",
        "# True negatives in the upper-left position\n",
        "# False negatives in the lower-left position\n",
        "# False positives in the upper-right position\n",
        "# True positives in the lower-right position\n",
        "\n",
        "confusion_matrix(y, model.predict(x))\n",
        "# Three true negative predictions: The first three observations are zeros predicted correctly.\n",
        "# No false negative predictions: These are the ones wrongly predicted as zeros.\n",
        "# One false positive prediction: The fourth observation is a zero that was wrongly predicted as one.\n",
        "# Six true positive predictions: The last six observations are ones predicted correctly."
      ],
      "metadata": {
        "id": "b8I6Sn8zvqPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the confusion matrix\n",
        "\n",
        "cm = confusion_matrix(y, model.predict(x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3OymlPFgwTea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "\n",
        "print(classification_report(y, model.predict(x)))\n",
        "\n",
        "#  It returns a report on the classification as a dictionary if you provide output_dict=True or a string otherwise."
      ],
      "metadata": {
        "id": "AJlpNv8pwvY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Improve the Model\n",
        "\n",
        "# regularization strength C equal to 10.0, instead of the default value of 1.0\n",
        "# the larger value of C means weaker regularization, or weaker penalization related to high values of 𝑏₀ and 𝑏₁.\n",
        "model = LogisticRegression(solver='saga')#, class_weight='balanced') # C=10.0,\n",
        "model.fit(x, y)\n",
        "model.score(x, y)"
      ],
      "metadata": {
        "id": "EcVF3gPCxWic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, model.predict(x))"
      ],
      "metadata": {
        "id": "PVJ6FgOtyA8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y, model.predict(x)))"
      ],
      "metadata": {
        "id": "PuDeSks-yFcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **StatsModels**\n",
        "\n"
      ],
      "metadata": {
        "id": "78CzZfZezJn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "GWbdLIxTzSz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. DATA\n",
        "\n",
        "# StatsModels doesn’t take the intercept 𝑏₀ into account, and you need to include the additional column of ones in x.\n",
        "x = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "x = sm.add_constant(x) # add_constant() takes the array x as the argument and returns a new array with the additional column of ones. \n",
        "# The first column of x corresponds to the intercept 𝑏₀. The second column contains the original values of x."
      ],
      "metadata": {
        "id": "uXl5PiYy0XKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. MODEL\n",
        "\n",
        "# Create a Model and Train It\n",
        "model = sm.Logit(y, x) # Note that the first argument here is y, followed by x.\n",
        "result = model.fit(method='newton')"
      ],
      "metadata": {
        "id": "LOiZUPW116zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain the values of 𝑏₀ and 𝑏₁. The first element is the intercept 𝑏₀, the second is the slope 𝑏₁.\n",
        "result.params"
      ],
      "metadata": {
        "id": "fY_8FQvD24U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Evaluate the Model\n",
        "\n",
        "result.predict(x)"
      ],
      "metadata": {
        "id": "hhT9ubYV3OS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual predicted outputs\n",
        "(result.predict(x) >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "xsVKkUbx3eXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "result.pred_table()"
      ],
      "metadata": {
        "id": "XL82Q6FD3uJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "\n",
        "result.summary()"
      ],
      "metadata": {
        "id": "txUn0MRb38uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.summary2()"
      ],
      "metadata": {
        "id": "CGGEJ-334Cnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient descent algorithm**"
      ],
      "metadata": {
        "id": "vwo4rfpVu0vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to_numpy()\n",
        "y = y.to_numpy().ravel()\n",
        "y = y.astype(str).astype(float).astype(int)"
      ],
      "metadata": {
        "id": "d-CZ6pWcvVDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = x\n",
        "Y = y"
      ],
      "metadata": {
        "id": "1v4SlD1Kvhe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "X = load_iris().data # numpy.ndarray\n",
        "Y = load_iris().target # numpy.ndarray"
      ],
      "metadata": {
        "id": "VTCNGKNHv1gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/multiclass-logistic-regression-from-scratch-9cc0007da372\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.special import softmax\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def loss(X, Y, W):\n",
        "    \"\"\"\n",
        "    Y: onehot encoded\n",
        "    \"\"\"\n",
        "    Z = - X @ W\n",
        "    N = X.shape[0]\n",
        "    loss = 1/N * (np.trace(X @ W @ Y.T) + np.sum(np.log(np.sum(np.exp(Z), axis=1))))\n",
        "    return loss\n",
        "\n",
        "def gradient(X, Y, W, mu):\n",
        "    \"\"\"\n",
        "    Y: onehot encoded \n",
        "    \"\"\"\n",
        "    Z = - X @ W\n",
        "    P = softmax(Z, axis=1)\n",
        "    N = X.shape[0]\n",
        "    gd = 1/N * (X.T @ (Y - P)) + 2 * mu * W\n",
        "    return gd\n",
        "\n",
        "def gradient_descent(X, Y, max_iter=1000, eta=0.1, mu=0.01):\n",
        "    \"\"\"\n",
        "    Very basic gradient descent algorithm with fixed eta and mu\n",
        "    \"\"\"\n",
        "    Y_onehot = onehot_encoder.fit_transform(Y.reshape(-1,1))\n",
        "    W = np.zeros((X.shape[1], Y_onehot.shape[1]))\n",
        "    step = 0\n",
        "    step_lst = [] \n",
        "    loss_lst = []\n",
        "    W_lst = []\n",
        " \n",
        "    while step < max_iter:\n",
        "        step += 1\n",
        "        W -= eta * gradient(X, Y_onehot, W, mu)\n",
        "        step_lst.append(step)\n",
        "        W_lst.append(W)\n",
        "        loss_lst.append(loss(X, Y_onehot, W))\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'step': step_lst, \n",
        "        'loss': loss_lst\n",
        "    })\n",
        "    return df, W\n",
        "\n",
        "class Multiclass:\n",
        "    def fit(self, X, Y):\n",
        "        self.loss_steps, self.W = gradient_descent(X, Y)\n",
        "\n",
        "    def loss_plot(self):\n",
        "        return self.loss_steps.plot(\n",
        "            x='step', \n",
        "            y='loss',\n",
        "            xlabel='step',\n",
        "            ylabel='loss'\n",
        "        )\n",
        "\n",
        "    def predict(self, H):\n",
        "        Z = - H @ self.W\n",
        "        P = softmax(Z, axis=1)\n",
        "        return np.argmax(P, axis=1)\n",
        "    \n",
        "#X = load_iris().data\n",
        "#Y = load_iris().target\n",
        "\n",
        "# fit model\n",
        "model = Multiclass()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# plot loss\n",
        "model.loss_plot()\n",
        "\n",
        "# predict \n",
        "model.predict(X)\n",
        "\n",
        "# check the predicted value and the actual value\n",
        "model.predict(X) == Y"
      ],
      "metadata": {
        "id": "Oh_s6rMCu2wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistics regression**"
      ],
      "metadata": {
        "id": "utW7HKg30OeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(solver='saga', max_iter=2000, multi_class='multinomial',random_state=0).fit(x, y)\n",
        "logreg.score(x,y)"
      ],
      "metadata": {
        "id": "w7-I-G0n0lt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('intercept ', logreg.intercept_[0])\n",
        "print('classes', logreg.classes_)"
      ],
      "metadata": {
        "id": "vgyTiBOW8oW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiclass Receiver Operating Characteristic (ROC)**"
      ],
      "metadata": {
        "id": "Sgr3sXjfABUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = radDF[[1,1]]"
      ],
      "metadata": {
        "id": "xQCpPTqHLHE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare data\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Radiomic First Order Features\n",
        "X = radDF[5:22, :]\n",
        "\n",
        "iris = load_iris()\n",
        "target_names = iris.target_names\n",
        "X, y = iris.data, iris.target\n",
        "y = iris.target_names[y]\n",
        "\n",
        "random_state = np.random.RandomState(0)\n",
        "n_samples, n_features = X.shape\n",
        "n_classes = len(np.unique(y))\n",
        "X = np.concatenate([X, random_state.randn(n_samples, 200 * n_features)], axis=1)\n",
        "(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ") = train_test_split(X, y, test_size=0.5, stratify=y, random_state=0)"
      ],
      "metadata": {
        "id": "mfbGfmigAChL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes"
      ],
      "metadata": {
        "id": "R0G_5plJCSVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a LogisticRegression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)"
      ],
      "metadata": {
        "id": "CCJt7uyAAWeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-vs-Rest multiclass ROC\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "label_binarizer = LabelBinarizer().fit(y_train)\n",
        "y_onehot_test = label_binarizer.transform(y_test)\n",
        "y_onehot_test.shape  # (n_samples, n_classes)"
      ],
      "metadata": {
        "id": "TH-MM5MOAon2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_binarizer.transform([\"virginica\"])"
      ],
      "metadata": {
        "id": "4zsVr4jKA2wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_of_interest = \"virginica\"\n",
        "class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
        "class_id"
      ],
      "metadata": {
        "id": "LsHAu5aDA3YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show ROC curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "RocCurveDisplay.from_predictions(\n",
        "    y_onehot_test[:, class_id],\n",
        "    y_score[:, class_id],\n",
        "    name=f\"{class_of_interest} vs the rest\",\n",
        "    color=\"darkorange\",\n",
        ")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
        "plt.axis(\"square\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nl7JmUebA5mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1oRQ637OBElb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}